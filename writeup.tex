\documentclass{article}
\usepackage{fullpage}
\usepackage{amsmath,amssymb,amsthm,bm,enumerate,mathtools}
\usepackage[hidelinks]{hyperref}
\usepackage{natbib}
\usepackage{xcolor}
\usepackage{graphics}

\newcommand{\E}{\mathbb{E}}
\renewcommand{\P}{\mathbb{P}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\mL}{\mathcal{L}}
\newcommand{\ip}[2]{\left\langle #1, #2 \right\rangle}
\newcommand{\ie}{\textit{i.e.,}\,}
\newcommand{\eg}{\textit{e.g.,}\,}
\newcommand{\nb}{\textit{n.b.,}\, }
\newcommand{\defn}{:=}
\newcommand{\var}{\mathop{\mbox{Var}}}
\newcommand{\cov}{\mathop{\mbox{Cov}}}

\newcommand{\comment}[1]{{\color{blue} \it #1}}

\newtheorem{thm}{Theorem}
\newtheorem{lem}{Lemma}
\newtheorem{prop}{Proposition}
\newtheorem{cor}{Corollary}
\theoremstyle{remark} 
	\newtheorem{rem}{Remark}
	\newtheorem{assn}{Assumption}
\theoremstyle{definition} 
	\newtheorem{mydef}{Definition} 
	\newtheorem{exmp}{Example} 
	\newtheorem{cond}{Condition}
	\newtheorem{conj}{Conjecture}


\begin{document}

% Intro:
%  - the infinitesimal model is useful because it is a "trait-only" model: it allows for predictions and modeling without knowing the underlying genetics.
%  - Its key properties are: (a) independence of seg noise, and (b) Gaussian-ness.
%  - It is basically a CLT, and in particular, (b) derives from a the CLT deriving from similar effect sizes.
%  - Motivating Q: there are other CLTs; can we generalize (b) to non-Gaussian effects, while keeping independence of seg variation?
% 
% Data motivation:
%  First, to see if this is worth asking we look at some data
%  ... and find that yeah, maybe effect sizes don't fall into the Gaussian domain of attraction.
% 
% First answer to the motivating question:  "No"
% Non-Gaussian effects (sometimes) imply nonindependence of transmission noise:
%   In at least some cases, natural non-gaussian models produce nonindependence:
%   1. all loci are uniformly small except there's one big one
%   2. loci are Cauchy
%   3. (is there a simple statement we can make more generally?)
% 
% Second answer, weaker but also "no":
%  - Observation: Let A and B be the contributions to parent phenotype, with A inherited by the offspring and B not. If A and B are independent, and seg noise is independent of parent phenotype, then A and B are Gaussian.
%  - When would A and B be asymptotically independent? One case is the rare-mutation limit that obtains a "thinned Poisson process" limit for A and B (I think: if all allele frequencies are at frequency O(1/M)?)
%  - (I have other thoughts to be sorted out here)
%  - Open Q (maybe?): is there any non-Gaussian model where transmission noise is independent of parental traits?
% 
% Simulations: let's see how this stuff works in practice
%  - neutral simulations
%  - also, stabilizing selection with theoretical motivation for form of stabilizing selection
%  - plot: (A) trait mean over time and trait distribution at the end
%  - plot: (B) (distrn of seg noise), (seg noise vs midparent), and (Radon-Nicodym deriv of conditional seg noise for a few values of midparent)
% 
% If we remove 'big loci' is what's left the infinitesimal model?
%  - people do this in practice (animal breeding papers)
%  - theory:  form of limiting conditional distribution
%  - theory: something about independence  (?? if we get there ??)
%  - plots (A) & (B) above from simulation, but for only small effects


\title{\large{\bf
    Large effects and the infinitesimal model
}}

\author{ \begin{small}
    Todd Parsons \&
    Peter Ralph
\end{small}}

\date{\today}
\maketitle

\begin{abstract}
    The infinitesimal model of quantitative genetics
    relies on the Central Limit Theorem to stipulate that
    under additive models of quantitative traits
    determined by many loci having similar effect size,
    the difference between an offspring's genetic trait component
    and the average of their two parents' genetic trait components
    is Normally distributed and independent of the parents' values.
    Here, we investigate how the assumption of similar effect sizes
    affects the model:
    in particular, if the tail of the effect size distribution is polynomial
    with exponent $\alpha < 2$, then sums of effects
    should be well-approximated by a ``stable distribution'',
    and find tail exponents between 1 and 2 in 
    effect sizes estimated by genome-wide association studies
    of many human disease-related traits.
    We show that the independence of offspring trait deviations from parental averages
    in many cases implies a Gaussian distribution,
    suggesting that non-Gaussian models of trait evolution must explicitly
    track the underlying genetics, at least for loci of large effect.
    We also characterize possible limiting trait distributions
    of the infinitesimal model with infinitely divisible noise distributions,
    and compare our results to simulations.
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

Much of the work to 
understand the evolution of quantitative traits in sexual species
has focused on models in quantitative genetics
that describe evolution of trait values without explicitly representing underlying genetic variation,
but in a manner deriving from our understanding of how genetic variation works in practice.
Such models are therefore
interestingly intermediate between mechanistic models of genetics and purely phenomenological.
% The action of natural selection on genetic variants in the absence of genetic variation is relatively well-understood (cite ewens),
% but tractable mathematical models of evolution for recombining species are elusive,
% at least with some results of when the model might be a good description of reality.
% For instance, a great deal of conceptual understanding and even quantitative predictions
% have been made assuming that the distribution of trait values in a population is Gaussian (cite Lande etcetera)
% despite the absence of a plausible model that would make this true (cite turelli and barton).
One concrete model of heritable trait evolution is the \emph{infinitesimal model},
which assumes a simple, explicit form for how the genetic component of offsprings' traits are determined by their parents:
they are Normally distributed, with the mean for each offspring equal to the average of the parents' values,
and a covariance independent of the parental trait values (but that depends on how they are related).
\citet{barton2017infinitesimal} give a history of the model
and a formal proof of conditions under which this would be a good approximation to reality,
which they extended to include dominance in \citet{barton2022infinitesimal}.

\comment{TODO: citations below}

As suggested by its name,
under the infinitesimal model the effects of any given genetic variant on the trait
is small (indeed, vanishing),
and selection-driven trait shifts are mediated by small changes in frequencies of many alleles of small effect.
However, empirical understanding of the genetic basis of trait variation in real-world species
often finds a significant portion of heritable variation explained by variants at only a few loci.
There are many possible explanations for this observation,
including selection or publication bias,
filters for larger-effect variants due to spatially varying selection (cite),
and/or grouping together of concordant alleles by linkage or inversions (cite).
However, it seems clear that in at least those cases where we understand the underlying molecular mechanisms,
mutations of large effect can be important in practice
(cite examples: insecticide resistance, coloration, etcetera).
The consensus in the field seems to be that traits exist on a spectrum between monogenic and polygenic,
and that many - if not most - are firmly in the intermediate, ``oligogenic'' region (cite),
where heritable trait variation is due both to segregating large- and small-effect variants.
Indeed, some sensible verbal models of the biological mechanisms by which a genetic change
comes to have an effect on an organism's trait
describe a hierarchy or range of ``proximities'' to the trait,
by which changes to more ``nearby'' genes have the possibility of causing larger changes in the trait
(cite omnigenic and others).
This suggests a mixture model for the effect size distribution:
perhaps the distribution of effect sizes within each gene is Normal,
but with a standard deviation that varies with ``proximity'' to the trait;
such mixtures can easily have large proportions of extreme values.

The Gaussian distribution appears thanks to ``the'' Central Limit Theorem,
i.e., the universality
of adding up a great many very small and independent things.
However, there is a wider class of Central Limit Theorems,
which describe the distributions of sums of a great many independent and exchangeable things:
the \emph{stable laws}.
Roughly speaking, these say that if we add together $n$ independent copies of a random variable $X$
for which $\P\{ X > t \}$ is proportional to $t^{-\alpha}$ for some $0 < \alpha < 2$,
then -- almost regardless of the details -- the result, scaled by $n^{1/\alpha}$,
is well-approximated by a universal form, an $\alpha$-stable distribution
(and the approximation becomes exact, as $n \to \infty$).
In such ensembles, single large entries can be important:
concretely, the largest of the $n$ copies will be of order $n^{1/\alpha}$,
so that e.g., for $\alpha=1$ a positive proportion of the sum of $n$ entries will be contributed by a single one.

This suggests exploring whether stable distributions might reasonably stand in for the Gaussian
in the infinitesimal model.
In this paper, we make preliminary explorations in that direction:
Do the results of \citet{barton2017infinitesimal}
carry over when the distribution of effect sizes falls in the domain of attraction of a stable law?
The immediate answer to this will be ``no'' --
in fact, we will see that independence of offsprings' deviations and midparent values \emph{implies} a Gaussian distribution in some sense.
This independence is a key reason why the infinitesimal model is tractable,
and so a conclusion is that additive models with non-Gaussian effects may not be well-approximated
by ``trait-only'' models that do not explicitly represent underlying genetic variation.
Having thus shown that ``infinitesimal models with non-Gaussian noise'' is on weak footing as a model of reality,
we then go on to analyze exactly these models.
(As motivation,
we have not shown that such models are \emph{not} good approximations to reality,
and it is interesting and perhaps informative to understand how the noise distribution affects results.)

Stable distributions are by no means new to population biology.
For instance, it is a long-standing question how often the motions of organisms
are better modeled by essentially Brownian random walks or by L\'evy processes (cite),
and a growing literature studies the effects of such power law distributions
on the shapes and dynamics of traveling waves such as biological invasions (cite).
\comment{Other examples?}
More directly analogous to the problem we study here, \citet{landis2012phylogenetic}
found that an $\alpha$-stable process (with $\alpha \approx 1.5$) fit the evolution of log endocranial volume
on the primate phylogeny
better than either a Brownian model.
It is also important to note that
the infinitesimal model implies a Gaussian distribution for the difference between an offspring's trait and their parents' average,
\emph{not} for the entire population.
The question of when the trait distribution in an evolving population
might be modeled as a Gaussian has been discussed extensively, e.g., by \comment{cite}.

The ways in which genetic variants affect an organisms' trait can be complex,
and interactions between alleles, between loci, and with the environment are often important in practice.
In fact, many traits claimed to be genetically determined
in fact only appear heritable through non-genetic means,
e.g., systematic inequalities in resource distribution partitioned by class or race. \comment{e.g., cite}
In this paper, we follow the literature in working with the relatively simple purely additive case
of a trait that can be decomposed into a sum across loci of the contributions of the alleles from each locus,
even omitting an independent effect of ``the environment''.
However, we emphasize that such models should \emph{not} always be the default for understanding biological variation,
especially for human traits.

%%%%%%%%%%%%%%%%%%%%%%
\subsection*{Notation}

We generally follow the notation of \citet{barton2017infinitesimal},
although in a simpler situation,
as we do not consider full pedigrees
but rather only the haploid offspring of a single set of haploid parents
(as produced, for instance, by a round of meiosis in a diploid stage),
and ignore non-genetic contributions to the trait;
so, below we say ``trait'' to mean ``genetic contribution to the trait''.

Suppose that the focal individual's trait is
$$
    Z_M = \sum_{\ell=1}^M \eta_\ell / M^{1/\alpha},
$$
where $\eta_\ell$ is the contribution of the allele carried at the $\ell^\text{th}$ locus.
The effects of the alleles carried by the two parents
are $\eta_\ell^{[1]}$ and $\eta_\ell^{[2]}$, respectively,
and their traits are
$Z_M^{[1]} = \sum_\ell \eta_\ell^{[1]} / M^{1/\alpha}$ and
$Z_M^{[2]} = \sum_\ell \eta_\ell^{[2]} / M^{1/\alpha}$.
We assume the loci are unlinked and inheritance is fair, so
letting $X_\ell$ be a family of Bernoulli(1/2) random variables that are independent of everything else,
$$
    \eta_\ell = X_\ell \eta_\ell^{[1]} + (1 - X_\ell) \eta_\ell^{[2]} .
$$
What we will call the \emph{transmission noise}, $R_M$,
is the offspring's trait minus the midparent value, $\bar Z_M$:
\begin{align*}
    \bar Z_M &= \frac{Z_M^{[1]} + Z_M^{[2]}}{2} \\
    R_M &= Z_M - \bar Z_M \\
        &= \sum_{\ell=1}^M
            \frac{
                X_\ell (\eta_\ell^{[1]} - \eta_\ell^{[2]})
                + (1 - X_\ell) (\eta_\ell^{[2]} - \eta_\ell^{[1]})
            }{ 2 } .
\end{align*}


%%%%%%%%%%%%%%%%%%%%%%
\section{Empirical observations}

It is mathematically intriguing to speculate what effect a power law effect size distribution
for would have on the induced evolutionary dynamics.
But, is there any evidence that non-Gaussian transmission noise is important in practice?
In this paper we focus primarily on the theory,
but first take a brief and imperfect look at what some data have to say on the topic.
To do this, we downloaded the GWAS results provided by~\citet{biobankSNPs}
for 7,221 phenotypes from 361,194 human individuals from the March 2018 release of the UK Biobank.
After filtering (see details below) we were left with 695 binary illness-related phenotypes.
Taken at face value, these provide for each phenotype a set of estimates of the additive effect
of the alternative allele at a set of single nucleotide polymorphisms (SNPs)
on the phenotype relative to the reference allele.
The phenotypes we consider were all binary and coded as 0/1,
so estimates could be thought of as additive adjustments to the risk
(so, effects are \emph{not} on a logit scale).
These estimates were obtained as the coefficient for the SNP in a simple linear model
fit to each phenotype for each SNP,
with the first 20 principal components and all combinations of age, age squared, and inferred sex as covariates;
we considered effects of those SNPs with a reported $p$-value less than $10^{-8}$.
There are a great many possible issues with these data;
however, the results seem consistent across many SNPs and phenotypes,
and we know of no reason that possible methodological artifacts
(e.g., confounding by uncorrected variables)
would specifically affect the decay of the tail of effect sizes.

Since the transmission noise is a sum of terms of the form
$$
    (X_\ell - 1/2) \eta_\ell^{[1]} + (1/2 - X_\ell) \eta_\ell^{[2]},
$$
where $\eta_\ell^{[i]}$ is the effect of the allele in parent $i$ at locus $\ell$,
the appropriate central limit theorem for the sum is determined by
the tail behavior of $|(X - 1/2) \eta| = |\eta|/2$,
where $X$ is Bernoulli(1/2) and $\eta$ is the effect
of a uniformly chosen allele at a uniformly chosen locus.
So, we'd like to know
if $\P\{|X|>2t\}$ is proportional to $t^{-\alpha}$,
i.e., the value of
$$
    \lim_{t \to \infty} \frac{ \log \P\{ |X| > 2 t \} }{ \log t } = \alpha ,
$$
if the limit exists.
Let $p_\ell$ be the minor allele frequency at the $\ell^\text{th}$ locus;
since the data we have assigns effect 0 to the major allele,
$\eta_\ell = 0$ with probability $1-p_\ell$.
Therefore, if we have estimated effects for $M$ SNPs
with minor allele frequency $p_\ell$ and effect size $e_\ell$ for the minor allele,
for $1 \le \ell \le M$,
then
$$
    \P\{ |\eta| > 2t \} \approx \frac{1}{M} \sum_{\ell : |e_\ell| > 2t} p_\ell .
$$
So, to obtain a per-trait estimate of $\alpha$,
we plot $\log \frac{1}{M} \sum_{\ell : |e_\ell| > t} p_\ell$ against $\log t$
for a sequence of values of $t$,
and fit a linear model to the tail
(which we take to be all values of $t$ for which the number of SNPs with absolute effect above $t$
is between 20 and 10\% of all SNPs).
Examples are shown in Figure~\ref{fig:example_snps}.

\begin{figure}
    \begin{center}
    \includegraphics{snp_effects/examples}
    \end{center}
    \caption{
        % TODO: cut this down to just 2 SNPs and move this figure to the supplement; change 'x' to 't' in axis labels.
        Tail distributions of frequency-weighted effects
        for twelve randomly chosen phenotypes.
        In each, for a phenotype with $N$ SNPs,
        effect sizes $e_i$ and frequencies $p_i$,
        the black line shows
        $\log \frac{1}{N} \sum_{i : |e_i| > t} p_i$ (vertical axis)
        against $\log t$ (horizontal axis);
        the red line shows the least-squares linear fit;
        each plot only covers the 10\% largest-effect SNPs.
        Legends show the coefficients of the red line; the slope on `x' is $\alpha$,
        the estimated exponent;
        ``num snps'' is the number of SNPs for the phenotype with $p$-value less than $10^{-8}$,
        and ``num cases'' is the reported number of the roughly 360,000 individuals
        recorded as having the listed phenotype.
        \label{fig:example_snps}
    }
\end{figure}

We applied this procedure to results from models fit on both sexes,
after removing phenotypes related to non-medical traits
(e.g., employment, drug treatments, and dietary choices).
This left us with 1,108 phenotypes for which we had enough data (e.g., enough significant SNPs)
to estimate the tail exponent.
We then restricted to phenotypes having non-missing numbers of ``cases'' and ``controls''
and a sample size of at least 300,000 (i.e., not more than 61,194 of 361,194 missing phenotypes),
and removed the 65 remaining phenotypes that are common (more than 10,000 cases),
as these often showed very different patterns
(e.g., effect size distributions).
This left us with 695 phenotypes;
plots including the 413 phenotypes removed by these last steps are provided in
Supplementary Figure~\ref{fig:unfiltered_hist}.

Resulting values of the tail exponent $\alpha$ are shown in Figure~\ref{fig:exponent_hist}.
Estimated tail exponents range from about 1 to 2.5,
and 28.9\% had estimated values less than 1.5.
A concern is that ``noisier'' phenotypes,
for which estimated effect sizes are less reliable,
might lead to larger estimated tail exponents;
for this reason, we looked for an association between
tail exponent and two proxies for power,
number of SNPs (i.e., number of SNPs with $p$-value less than $10^{-8}$)
and number of cases.
Interestingly, the relationship is nonmonotonic,
with exponents closer to $\alpha=2$ for phenotypes with around 1000 cases,
and lower exponents for both rarer and more common phenotypes.
(A similar pattern is seen for ``number of SNPs'',
but this may be due to association with power and hence number of cases.)
This may indicate a statistical artifact,
or it may be a result of biological differences in genetic architecture
between more and less common phenotypes.

\begin{figure}
    \begin{center}
    \includegraphics{snp_effects/results_10}
    \end{center}
    \caption{
        Estimated values of the tail exponent, $\alpha$,
        for 775 illness-related binary phenotypes:
        \textbf{(A)} distribution of values; and plotted against
        \textbf{(B)} number of SNPs, and
        \textbf{(C)} number of cases.
        \label{fig:exponent_hist}
    }
\end{figure}


%%%%%%%%%%%%%%%%%%%%%%
\section{Independence and the Gaussian assumption}

We know from \citet{barton2017infinitesimal} that if the $\eta^{[i]}_\ell$ are
independent with mean zero and $\sum_{\ell=1}^M \var[\eta_\ell]/M \to \sigma^2$,
then with $\alpha=2$,
the traits $(Z_M, Z_M^{[1]}, Z_M^{[2]})$ converge in distribution to a multivariate Gaussian distribution
$(Z, Z^{[1]}, Z^{[2]})$ for which $Z - (Z^{[1]} + Z^{[2]})/2$ is independent of $Z^{[1]}$ and $Z^{[2]}$.

Perhaps surprisingly, there is a converse --
in at least some situations,
independence of transmission noise implies a Gaussian distribution.
To see this,
divide the parental loci into groups according to the results of inheritance,
defining
\begin{align*}
    U_M^{[1]} &= \sum_{\ell=1}^M X_\ell \eta_\ell^{[1]}  ,
    \qquad \qquad
    V_M^{[1]} = \sum_{\ell=1}^M (1-X_\ell) \eta_\ell^{[1]} ,  \\
    U_M^{[2]} &= \sum_{\ell=1}^M (1-X_\ell) \eta_\ell^{[2]} ,
    \qquad \qquad
    V_M^{[2]} = \sum_{\ell=1}^M X_\ell \eta_\ell^{[2]}  ,
\end{align*}
so that 
$Z_M^{[1]} = U_M^{[1]} + V_M^{[1]}$ and
$Z_M^{[2]} = U_M^{[2]} + V_M^{[2]}$, while
$Z_M = U_M^{[1]} + U_M^{[2]}$ is the transmitted portion of the parental genomes,
and we can define $V_M = V_M^{[1]} + V_M^{[2]}$ to be the untransmitted portion.
Furthermore,
\begin{align*}
    \bar Z_M = \frac{Z_M + V_M}{2}
    \qquad \text{ and } \qquad
    R_M = \frac{Z_M - V_M}{ 2 } .
\end{align*}

Now, note that if inheritance (the $X_\ell$) is independent of the per-locus effects ($\eta_\ell^{[i]}$),
the latter are all independent of each other,
and all effects at a given locus are drawn from the same distribution,
then the inherited allele, 
$\eta_\ell^{[1]} X_\ell + \eta_\ell^{[2]} (1-X_\ell)$
is independent of (and has the same distribution as)
the non-inherited allele,
$\eta_\ell^{[1]} (1-X_\ell) + \eta_\ell^{[2]} X_\ell$
-- they are simply two independent draws from the distribution of effects at locus $\ell$.
Therefore, the inherited alleles that sum to $Z_M$
are independent of the non-inherited alleles that sum to $V_M$.

The Kac-Bernstein theorem states that if two independent random variables
have the property that if their sum and difference are independent of each other,
then the random variables have a joint Gaussian distribution
(\citet{kac1939characterization,bernstein1941property},
and see \citet{kagan1973characterization} for many much more general results).
Since $R_M$ is (half) the difference and $\bar Z_M$ is (half) the sum
of $Z_M$ and $V_M$, and $Z_M$ and $V_M$ are independent,
if we assume that also $R_M$ and $\bar Z_M$ are independent,
then both are therefore jointly Gaussian.

We have shown the following:

\begin{prop}\label{prop:parental_contribs}
    Suppose that $\{\eta_\ell^{[i]}\}$ are independent for all $\ell$ and $i$,
    that the distribution of $\eta_\ell^{[i]}$ only depends on $\ell$,
    and that $\{X_\ell\}$ are independent of $\{\eta_\ell^{[i]}\}$.
    If the transmission noise $R_M$ is independent of the midparent value $\bar Z_M$,
    then $R_M$ and $\bar Z_M$ are jointly Gaussian.
\end{prop}

% A similar statement holds for the offspring of two parents in a pedigree,
% using the Skitovich-Darmois theorem \citet{kagan1973characterization},
% except that the portion of the genome shared in common by the parents is unconstrained.

Since models can be easily set up for which trait distributions are not Gaussian,
the implication of this is that for such models, independence of transmission noise
is not likely a good assumption.
Note that the proof does not depend on independence of the $X_\ell$:
indeed, alleles may be inherited together,
although in practice this would quickly create dependencies between nearby allelic effects.
Also note that it is \emph{not} usually true that the components --
for instance, $U_M^{[1]}$ and $U_M^{[2]}$ --
are independent of each other.

The presence of a large effect polymorphic allele
makes $R_M$ and $\bar Z_M$ dependent:
consider the extreme case where $\eta^{[i]}_\ell$ are i.i.d.{} with variance 1 for $\ell \ge 2$,
while $\eta^{[i]}_1 = \pm 10$ with probability 1/2 each,
and $Z^{[i]} = \eta_1^{[i]} + \sum_{\ell=2}^M \eta_\ell^{[i]} / \sqrt{M}$.
Then in the limit $R_M$ depends strongly on parental trait values:
if $Z^{[1]} \approx Z^{[2]}$ and so $\bar Z \approx \pm 10$ then most likely
$\eta_1^{[1]} = \eta_1^{[2]}$ and so $R$ is Normal with variance 1/2;
but if $\eta_1^{[1]} \neq \eta_1^{[2]}$ (and so $\bar Z \approx 0$)
then $R$ is close to $+5$ or $-5$ with equal probability.


%%%%%%%%%%%%%%%%%%%%%%
\section{Extending the infinitesimal model}  % TODD

\comment{Proposal: change $1 + \mu$ to $f$ (or, something else, but a single letter).}

\comment{Copied from \texttt{eugene\_notes.tex}:}

Let $X$ be a population of size $N$, recorded as the empirical distribution on phenotypes
\begin{align*}
    X = \frac{1}{N} \sum_{i=1}^N \delta_{x_i} .
\end{align*}
So, $X$ is a point measure of total mass 1 on $\R$.
This evolves as a Moran process under the infinitesimal model
with death rates depending on state $x$.
Concretely, an individual whose phenotype is $x$
dies at rate $1 + \mu(x)$
and is replaced by a new individual of phenotype
\begin{align*}
  \frac{y + z}{2} + \xi ,
\end{align*}
where $y$ and $z$ are independent draws from $X$
and $\xi$ is an independent draw from the transmission noise distribution.
Let $p_\xi$ denote the distribution of $\xi$,
and $\nu(X)$ denote the distribution of $\frac{y + z}{2} + \xi$.
This has generator
\begin{align*}
    \mL \Phi(X)
    &=
    \int \int \int \int
    \left( \Phi\left( X + \frac{1}{N} \delta_{(y+z)/2 + \xi} - \frac{1}{N} \delta_x \right) - \Phi(X) \right)
    (1 + \mu(x)) X(dx) X(dy) X(dz) p_\xi(d\xi) \\
    &=
    \int \int
    \left( \Phi\left(X + \frac{1}{N} \delta_u - \frac{1}{N} \delta_x\right) - \Phi(X) \right)
    (1 + \mu(x)) X(dx) \nu(X)(du) .
\end{align*}

For a test function $\phi$, setting $\Phi(X) = \ip{\phi}{X} := \int \phi(x) X(dx)$
we get the first moment
\begin{align*}
    \mL \ip{\phi}{X}
    &=
    \frac{1}{N} \int \int \int \int
    \left( \phi \left( \frac{y+z}{2} + \xi \right)
         - \phi(x) \right)
    (1 + \mu(x)) X(dx) X(dy) X(dz) p_\xi(d\xi) \\
    &=
    \frac{1}{N} \ip{\phi}{\nu(X)}\ip{1+\mu}{X}
    - \frac{1}{N} \ip{\phi}{(1+\mu) X} .
\end{align*}
Note that for $Y$ another finite measure on $\R$,
the Fr\'echet derivative \comment{(is that the right name?)} of $X$ in the direction of $Y$
satisfies $\ip{\phi}{\partial_Y X} = \lim_{\epsilon \to 0} \epsilon^{-1} (\ip{\phi}{X + \epsilon Y} - \ip{\phi}{X}) = \ip{\phi}{Y}$,
so that this is a first derivative in the direction of the measure
$$ \ip{1+\mu}{X} \nu(X) - (1+\mu) X . $$

More generally, if $\Phi(X) = \prod_i \ip{\phi_i}{X}$ then
\begin{align*}
    \mL \Phi(X)
    &=
    \frac{1}{N} \sum_i \left( 
        \ip{1+\mu}{X} \ip{\phi_i}{\nu(X)}  - \ip{\phi_i}{(1+\mu)X}
    \right)
    \prod_{j \neq i} \ip{\phi_j}{X} 
    + O(1/N^2) .
\end{align*}
This implies that after rescaling time by $N$
and suitable other caveats,
the limiting process is a deterministic flow in the direction of 
$\nu(X) \ip{1+\mu}{X} - (1+\mu)X$.

\paragraph{Stable measures}
If $Z$ is a fixed point of this flow,
then $\nu(Z)\ip{1+\mu}{Z} = (1+\mu)Z$.
In other words, any measure $Z$ that is a fixed point has the property that
(the average of two independent draws plus transmission noise)
is equal in distribution to
(a $1+\mu$-weighted draw).
Concretely, with $A$, $B$, and $C$ independent draws from $Z$,
\begin{align} \label{eqn:ABC_condition}
    \E\left[ f\left( \frac{A+B}{2} + \xi \right) \right]
    &=
    \frac{\E\left[ f(C) (1+\mu(C)) \right]}{\E[1+\mu(C)]} .
\end{align}

\comment{Copied from \texttt{MeanFlow.tex}:}

Assume that $Z$ is a finite measure, and without loss of generality normalized to have total mass one.

Throughout, I'll be using the characteristic function of $Z$, which I'll denote by 
\[
	\phi(\theta) = \mathbb{E}\left[e^{i\theta Z}\right],
\]
and the characteristic function of $\xi$, $\Phi(\theta)$.

\section{No Selection}

First, consider the case without selection, so $\mu$ is a constant.  Then, our condition on the characteristic function simplifies to
\begin{equation}\label{CHARACTERISTIC}
	{\textstyle \phi\left(\frac{\theta}{2}\right)^{2}} \Phi(\theta) %e^{-\frac{\eta^{2}\theta^{2}}{2}} 
	= \phi(\theta),
\end{equation}
\ie $\phi(\theta)$ is a fixed point of $F$, where
 \[
	F(\phi)(\theta) = {\textstyle \phi\left(\frac{\theta}{2}\right)^{2}} \Phi(\theta).
\]
In particular, we can characterize all possible fixed points by considering the iterates of an arbitrary characteristic function, $\varphi(\theta)$, for  any distribution on $\mathbb{R}$.  

Iterating $F$ $n$ times, we get
\[
	F^{(n)}(\varphi)(\theta)
	=  {\textstyle \varphi\left(\frac{\theta}{2^{n}}\right)^{2^{n}}}\prod_{k=1}^{n-1} {\textstyle \Phi\left(\frac{\theta}{2^{k}}\right)^{2^{k}}},
\]
so that
\[
	\phi(\theta) = \lim_{n \to \infty} \varphi\left(\frac{\theta}{2^{n}}\right)^{2^{n}}\prod_{k=1}^{n-1}\Phi\left(\frac{\theta}{2^{k}}\right)^{2^{k}}
\]
is a fixed point whenever this limit exists.  

Since $\varphi$ and $\Phi$ are characteristic functions, they are absolutely continuous and $\phi(0) = 1$, and thus non-zero in a neighbourhood of 0. In particular, $\psi(\theta) = \ln{\varphi}(\theta)$ and $\Psi(\theta) = \ln{\Phi(\theta)}$ exist in some neighbourhood of 0 as well.  From the above, we have
\[
	\ln{F^{(n)}(\varphi)(\theta)} = {\textstyle 2^{n} \psi\left(\frac{\theta}{2^{n}}\right)} 
		+ \sum_{k=1}^{n-1}  {\textstyle 2^{k} \Psi\left(\frac{\theta}{2^{k}}\right)}.
\]

\subsection{Noise Terms}

We now analyse the component arising from the noise $\xi$.  First, we consider the case when $\Psi(\theta)$ is twice continuously differentiable, so $\xi$ has finite mean $m = \Psi'(0)$
and variance $\eta^{2} = \Psi''(0)$.   Taylor's theorem then tells us that for $\theta$ sufficiently small, 
\[
	\Psi(\theta) = m\theta + \frac{\eta^{2}}{2} \theta^{2} + r(\theta)\theta^{2},
\]
where $r(\theta) \to 0$ as $\theta \to 0$.  Then,
\begin{align*}
	 \sum_{k=1}^{n-1}  {\textstyle 2^{k} \Psi\left(\frac{\theta}{2^{k}}\right)}
	 &=  \sum_{k=1}^{n-1} 2^{k} {\textstyle \left(m \frac{\theta}{2^{k}} - \frac{\eta^{2}}{2}  \frac{\theta^{2}}{2^{2k}}
		+ r\left(\frac{\theta}{2^{k}}\right)\frac{\theta^{2}}{2^{2k}}\right)}\\
	&= (n-1) m - \eta^{2} \theta^{2} (1 - 2^{-n+1}) 
		+ \sum_{k=1}^{n-1} {\textstyle r\left(\frac{\theta}{2^{k}}\right)\frac{\theta^{2}}{2^{k}}}
 \end{align*}

Immediately, we see that for the limit to exist, we must have $m = 0$; if we assume that $r(\theta) \equiv 0$, so that the noise is $N(0,\eta^{2})$, then the limiting distribution is $N(0,2\eta^{2})$. We note that when  $r(\theta)$ is non-zero, we don't expect the higher order terms to vanish.

Now, consider the case when $\Psi(\theta)$ corresponds to a stable law, so
\[
	\Psi(\theta) = im\theta + c|\theta|^{\alpha} (1-i\beta \text{sgn}(\theta)\omega_{\alpha}(\theta))
\]
for $\alpha \in (0,2]$, $\beta \in [-1,1]$, $c \geq 0$, and $m \in \mathbb{R}$ and
\[
	\omega_{\alpha}(\theta) = \begin{cases}
		\tan{\frac{\pi\alpha}{2}} & \text{if $\alpha \neq 1$, and}\\
		-\frac{2}{\pi}\ln{|\theta|} & \text{if $\alpha = 1$.}
	\end{cases}
\]
We then have
\begin{multline*}
	 \sum_{k=1}^{n-1}  {\textstyle 2^{k} \Psi\left(\frac{\theta}{2^{k}}\right)}
	 =  \sum_{k=1}^{n-1} im\theta + 2^{(1-\alpha)k} c|\theta|^{\alpha} {\textstyle\left(1-i \beta\text{sgn}(\theta)\left(\frac{\theta}{2^{k}}\right)
	 	 \omega_{\alpha}\left(\frac{\theta}{2^{k}}\right)\right)}\\
	= 
	\begin{cases}
		 im(n-1)\theta + c|\theta|^{\alpha}\frac{1-2^{(1-\alpha)n}}{1-2^{1-\alpha}}\left(1-i\beta \text{sgn}(\theta) \tan{\frac{\pi\alpha}{2}}\right) & \text{if $\alpha \neq 1$, and}\\	
		 \begin{multlined}
		 im(n-1)\theta + c|\theta|^{\alpha}  \left(\frac{1-2^{(1-\alpha)n}}{1-2^{1-\alpha}}
		 \left(1+i \beta \text{sgn}(\theta)\frac{2}{\pi}\ln{|\theta|} \right)\right.\\
		\left. -i\beta \text{sgn}(\theta) \frac{2^{1-\alpha} + (n(2^{1-\alpha}-1)-1)2^{(1-\alpha)n})}{(1-2^{1-\alpha})^{2}}\frac{2}{\pi}\ln{2}
		\right)    
		\end{multlined}
		& \text{if $\alpha = 1$.}
	\end{cases}
\end{multline*}
This converges as $n \to \infty$ if and only if $m = 0$ and $\alpha \ge 1$, in which case the limit is 
\[
	 \frac{c}{1-2^{1-\alpha}}|\theta|^{\alpha}\left(1-i\beta \text{sgn}(\theta) \tan{\frac{\pi\alpha}{2}}\right), 
\]
which corresponds to a $\left(\alpha,\beta, \frac{c}{1-2^{1-\alpha}},0\right)$-stable law.

\subsection{Reproductive Terms}

We now consider the terms $2^{n} \psi\left(\frac{\theta}{2^{n}}\right)$, which we call the reproductive terms.  Proceeding as below, we consider the limit
%We note that this does not exclude the possibility of distributions without a mean; % \eg if $\eta =0$, then \eqref{CHARACTERISTIC} is satisfied by the family of Cauchy distributions with characteristic functions $\phi(\theta) = e^{i m \theta - \gamma |\theta|}$; one can check that these are the only stable laws satisfying \eqref{CHARACTERISTIC}.%  One can similarly exclude the stable laws without mean ($\alpha \leq 1$) by inspection in the case of $\eta > 0$. 
%Now, to exhaust all possibilities, observe that by iterating, we we also have that 
%\[
%	\psi(\theta) = 2^{n}\psi\left(\frac{\theta}{2^{n}}\right) 
%\]
%\ie we must have 
\[
		\alpha(\theta) = \lim_{n \to \infty} 2^{n}\psi\left(\frac{\theta}{2^{n}}\right).
\]
Because $\psi(\theta)$ is the logarithm characteristic function, it must be uniformly continuous and vanish at 0, and thus $\alpha(\theta)$ as well.  We also have that for all integers $k$, 
\[
	\alpha(2^{k} \theta) = \lim_{n \to \infty} 2^{n}\psi\left(\frac{2^{k} \theta}{2^{n}}\right) =  \lim_{n \to \infty} 2^{k} 2^{n-k} \psi\left(\frac{\theta}{2^{n-k}}\right) = 2^{k} \alpha(\theta).
\]
In particular, we see that given any continuous function $\alpha(\theta)$, $\theta \in [1,2]$, such that $\alpha(2) = 2\alpha(1)$, $\alpha$ is defined for all positive reals.  We can extend the definition to the negative reals via the Hermitian property for $\phi(\theta)$: $\phi(-\theta) = \overline{\phi(\theta)}$ implies that $\alpha(-\theta) = \overline{\alpha(\theta)}$. 

Now, from the above, 
\[
	\frac{\alpha(\theta)}{\theta} = \frac{\alpha(2^{k} \theta)}{2^{k}\theta} \to \alpha'(0+),
\]
as $k \to - \infty$ if the latter exists (\ie there is a unique left-hand limit at zero).  In this case, setting $-\gamma + i m = \alpha'(0+)$, we have
\[
	\alpha(\theta) = \begin{cases} 
		i m\theta - \gamma \theta & \text{if $\theta \geq 0$, and}\\
		i m\theta + \gamma \theta & \text{if $\theta < 0$}.
	\end{cases}
\]
\ie if $\gamma > 0$, then $e^{\alpha(\theta)} = e^{im \theta -\gamma|\theta|}$ is the characteristic function of a Cauchy distribution and $\phi(\theta)$ is the characteristic function of the sum of Cauchy and Gaussian random variables, whereas if $\gamma = 0$, then $e^{\alpha(\theta)} = e^{im \theta}$ is the Fourier transform of a Dirac mass at $m$, so the limiting random variable is the Gaussian $N(m,\eta^{2})$. 

Finally, we remark that if $\frac{\alpha(\theta)}{\theta}$ is non-constant for $\theta > 0$, then $\alpha'(0+)$ does not exist. 

\subsection{Other Solutions?}

We would naturally like to know if these two exhaust the possible solutions.  To this end, we recall Bochner's theorem, which tells us that a function $\phi(\theta)$ is the characteristic function of a random variable if and only if
\begin{enumerate}[(i)]
\item $\phi(\theta)$ is uniformly continuous,
\item $\phi(0) = 1$,
\item $\phi(-\theta) = \overline{\phi(\theta)}$, and
\item $\phi(\theta)$ is \textit{positive definite}: for all $n$ and all $\theta_{1},\ldots,\theta_{n} \in \mathbb{R}$, the matrix with entries
\[
	a_{ij} = \phi(\theta_{i}-\theta_{j})
\]
is positive definite.
\end{enumerate}
Given $\alpha(\theta)$ as above, the corresponding function $\phi(\theta) = e^{\alpha(\theta)-\eta^{2}\theta^{2}}$ 
or $\phi(\theta) = e^{\alpha(\theta) - \frac{c}{1-2^{1-\alpha}}|\theta|^{\alpha}\left(1-i\beta \text{sgn}(\theta) \tan{\frac{\pi\alpha}{2}}\right)}$ satisfies the first three criteria.  We will now seek to identify which $\alpha(\theta)$ result in positive definite $\phi(\theta)$.  When $\alpha(\theta) = im \theta -\gamma|\theta|$ for $\gamma > 0$, this is immediate, as $e^{\alpha(\theta)}$ is then the characteristic function of a Cauchy random variable.

We can also easily exclude the case $\gamma < 0$ using a simple consequence of positive definiteness in the case when $n=2$ (name criterion): if $\phi(\theta)$ is positive definite, then $|\phi(\theta)| \leq 1$.  For us, this requires that 
\[
	\Re \alpha(\theta) \leq  \eta^{2} \theta^{2},\; resp. \; < \frac{c}{1-2^{1-\alpha}}|\theta|^{\alpha}
\]
which is violated for small values of $\theta$ when $\gamma < 0$ (recall $\alpha > 1$). 

\noindent\emph{Question:} how can we use positive definiteness to exclude $\alpha(\theta)$ with $\Re \alpha(\theta) \leq  \eta^{2} \theta^{2}$ so that $\alpha'(0+)$ does not exist?

\begin{rem}
Polya has shown that if $\phi(\theta)$ is convex and satisfies the first three criteria of Bochner's theorem, then $\phi(\theta)$ is a characteristic function.  In our case, if $\alpha(\theta)$ is convex, then $e^{\alpha(\theta)}$ is as well; a proof-by-picture, however, shows that the only choice of $\alpha(\theta)$ that is convex (or concave, for that matter) for $\theta > 0$ is a linear function, so Polya's criterion doesn't give us any new characteristic functions.
\end{rem}


\subsection{Stabilizing Selection}
    \label{sec:stabilizing_selection}

\subsubsection{Gaussian Solution}
    \label{sec:stabilizing_gaussian}

Now, consider the case when $1+ \mu(x) = e^{a x^{2}}$. 
In this case there is a Gaussian solution: suppose $Z$ is Gaussian with mean $m$ and variance $\sigma^{2}$.  Then,
\[
	\phi(\theta) = e^{i m \theta - \frac{1}{2} \sigma^{2} \theta^{2}}.
\]
Moreover, provided $a < \frac{1}{2\sigma^{2}}$, we can explicitly compute $\frac{\mathbb{E}\left[e^{i \theta Z}(1+\mu(Z))\right]}{\mathbb{E}[1+\mu(Z)]}$  to conclude that
if $\xi$ is Gaussian with mean zero and variance $\eta^2$,
then equation~\eqref{eqn:ABC_condition} with $f(x)=e^{i\theta x}$ is
\[
	e^{i m \theta - \frac{1}{2} \left(\frac{\sigma^{2}}{2} + \eta^{2}\right)\theta^{2}}
	= e^{i \frac{m}{1-2 a \sigma^{2}}\theta 
		- \frac{1}{2} \frac{\sigma^{2}}{1-2 a \sigma^{2}}\theta^{2}},
\]
which, equating real and complex components, has a solution provided $m = 0$ and
\[
	\sigma^{2} = \frac{\sqrt{16 a^{2} \eta^{4} + 24 a \eta^{2}+1} - 4a \eta^{2} -1}{4a} 
	=  2\eta^{2}(1-4a\eta^{2}) + O(a^{2}).
\]

\subsubsection{Cauchy Solution}
    \label{sec:stabilizing_cauchy}

In the case of a Cauchy random variable, we again have an explicit expression for the probability distribution, which, proceeding as above, allows us to construct an explicit solution when $1+ \mu(x) = \frac{\delta^{2}}{\gamma^{2}} \frac{\gamma^{2} + x^{2}}{\delta^{2} + x^{2}}$ for $\delta > \gamma > 0$ and the noise $\xi$ is given by a $\text{Cauchy}(0,\delta-\gamma)$ random variable (\ie corresponding to a stable $(0,0,\delta-\gamma,0)$ law).

If we now suppose that $Z$ is a $\text{Cauchy}(0,\gamma)$ random variable.  Then $Z$ has probability density function $\frac{\gamma}{\pi} \frac{1}{\gamma^{2} + x^{2}}$, whereas 
\[
	\frac{\mathbb{E}\left[e^{i \theta Z}(1+\mu(Z))\right]}{\mathbb{E}[1+\mu(Z)]}
	= e^{-\delta |\theta|} = e^{-2\gamma \left|\frac{\theta}{2}\right|-(\delta-\gamma)|\theta|}
\]
which we recognize as being equal to $\phi\left(\frac{\theta}{2}\right)^{2} \Phi(\theta)$,
and so solves equation~\eqref{CHARACTERISTIC}.

%(here, see a saturating cost to being away from the optimal phenotype $x = 0$: the mortality is maximized at  $\frac{\beta^{2}}{\alpha^{2}}$.

\bigskip

\noindent\emph{Question:} other stable laws?


%%%%%%%%%%%%%%%%%%%%%%
\section{Simulations}

Next we turn to simulation,
in which we can easily include realistic recombination (instead of unlinked loci) and selection.
We used SLiM v4 \citep{haller2022slim4}
to simulate a discrete-time approximation to the continuous-time Moran model described above
as follows.
Individuals are diploid, hermaphroditic, and sexual;
the genome is of length $10^8$bp with a uniform recombination rate of $10^{-8}$ crossovers per bp;
mutations occur at a rate of $10^{-9}$ per bp.
Each new mutation is independently assigned an ``effect''
drawn from the ``effect size distribution'' (and will be either Gaussian or Cauchy).
The phenotype of each individual is determined additively
by summing the effects of all mutations they carry across both chromosomes.
Let $f(z)$ be the death rate of an individual with phenotype $z$,
and let $dt$ be a small constant (we took $dt=0.01$).
In all plots, one time unit is approximately one generation.
Then, at each time step
each individual dies with probability $1 - \exp(-dt f(z))$;
if there are $k$ such individuals chosen to die in a given time step,
then we choose $k$ individuals uniformly and without replacement
to produce new offspring;
for each such reproduction event the parent chooses a mate uniformly at random from the population.
This maintains the population at a fixed size, $N$.
(Note that individuals may self and individuals chosen to die may also reproduce,
but in a large population these details should be unimportant.)

\begin{figure}
    \begin{center}
        \includegraphics{sims/neutral_trait_traces}
    \end{center}
    \caption{
        Median trait values over time \textbf{(A and C)}
        and distributions of final trait values \textbf{(B and D)}
        in neutral simulations
        with Gaussian \textbf{(A and B)} and Cauchy \textbf{(C and D)}
        effect size distributions.
        Simulations were begun with no genetic variation,
        had populations of size $N=1000$,
        a genome of length $L=10^8$ bp and mutation rate of $\mu=10^{-9}$ per bp per generation;
        the effect size distributions were
        Normal with mean 0 and standard deviation $1/\sqrt{4NL\mu}$
        and Cauchy with center 0 and scale $1/(4NL\mu)$, respectively.
        \label{fig:trait_distrns}
    }
\end{figure}

\begin{figure}
    \begin{center}
        \includegraphics{sims/neutral_seg_noise}
    \end{center}
    \caption{
        Segregation noise with Gaussian \textbf{(A-C)} and Cauchy \textbf{(D-F)} effect size distributions,
        from the same simulations shown in Figure~\ref{fig:trait_distrns},
        for all individuals born during the last 1,000 time units of the simulation.
        \textbf{(A,D)} Segregation noise (offspring trait minus midparent) plotted against midparent.
        \textbf{(B,E)} Histograms of transmission noise.
        \textbf{(B,E)} Enrichment in quantiles of transmission noise conditional on midparent value.
        To compute the latter,
        let $q_0, q_2, q_4, \ldots, q_{98}, q_{100}$ divide the distribution of transmission noise
        into 50 bins with roughly equal numbers in each (i.e., the quantiles),
        let $p_k(a,b)$ denote the proportion of the offspring of parents with midparent value
        is in $[a, b)$ whose transmission noise is in $[q_{k-1}, q_k)$,
        and let $p_k$ be the proportion of all offspring with segregation noise in $[q_{k-1}, q_k)$
        (so, $p_k \approx 0.02$).
        Then, each line shows $p_k(a,b)/p_k$
        plotted against the midpoint of the corresponding quantile bin $(q_{k-1},q_k)$,
        for $(a,b)$ chosen to span the 5\% of midparents centered on:
        (red) the 10\% quantile,
        (black) the median, and
        (green) the 90\% quantile of midparent value.
        \label{fig:seg_noise}
    }
\end{figure}

We first consider the neutral case (i.e., with $f \equiv 1$).
As shown in Figure~\ref{fig:trait_distrns},
a simulation with a Cauchy effect size distribution, unsurprisingly,
has a distribution of trait values with more extreme values
and a rougher path of population median trait value over time
than does a simulation with a Gaussian effect size distribution.
Indeed, the sum of all effects along the path from the start of the simulation
to an arbitrary individual will approximate either Brownian motion (in the Gaussian case)
or a Cauchy process (in the Cauchy case).
Figure~\ref{fig:seg_noise} shows how transmission noise
depends on midparent value.
In the Gaussian case, transmission noise is Gaussian and independent of midparent value,
as shown by the horizontal lines at 1.0 in Figure~\ref{fig:seg_noise}C. 
On the other hand, in the Cauchy case we can see from either Figure~\ref{fig:seg_noise}D or F
that transmission noise depends strongly on midparent trait,
as we would expect in the presence of several large-effect alleles.

\begin{figure}
    \begin{center}
        \includegraphics{sims/selected_trait_traces}
    \end{center}
    \caption{
        As in Figure~\ref{fig:trait_distrns},
        except under a model of stabilizing selection (see text for details).
        \label{fig:sel_trait_distrns}
    }
\end{figure}

\begin{figure}
    \begin{center}
        \includegraphics{sims/selected_seg_noise}
    \end{center}
    \caption{
        As in Figure~\ref{fig:seg_noise},
        except under a model of stabilizing selection (see text for details).
        \label{fig:sel_seg_noise}
    }
\end{figure}

We next compared two situations of stabilizing selection, motivated by the results above
\comment{TODO: refer to where?}:
(1) the effect size distribution was Gaussian with mean zero and standard deviation 1.0
and $f(z) = e^{\alpha z^2}$; and
(2) the effect size distribution was Cauchy, centered at zero and with width $\delta - \gamma$
and $f(z) = (\delta/\gamma) (\gamma + z^2) / (\delta + z^2)$ with $\delta=0.5$ and $\gamma=0.2$.
Figures~\ref{fig:sel_trait_distrns} and~\ref{fig:sel_seg_noise}
show that the picture is largely unchanged by stabilizing selection
except that, unsurprisingly, the median trait no longer wanders unconstrained
(but still shows substantially larger fluctuations under the Cauchy model).

\begin{figure}
    \begin{center}
        \includegraphics{sims/neutral_seg_noise_small}
    \end{center}
    \caption{
        As in Figure~\ref{fig:seg_noise},
        except computed using only mutations with absolute value effect size less than 0.1.
        The same quantities for the simulations of Figure~\ref{fig:sel_seg_noise}
        with stabilizing selection are shown in Figure~\ref{fig:sel_seg_noise_small}.
        \label{fig:seg_noise_small}
    }
\end{figure}


However,
the two models look much more similar when considering only alleles of small effect.
Figure~\ref{fig:seg_noise_small} shows that ``midparent value''
and ``transmission noise'' computed using only mutations with effect size less than 0.2
(excluding less than 1\% of mutations)
are quite close to independent.
The result does not depend strongly on the cutoff chosen,
and are similar even if less 0.1\% of mutations are excluded.

%%%%%%%%%%%%%%%%%%%%%%%
\section{Discussion}

A substantial challenge for the field is to develop tractable models of trait evolution
that include contributions of both ``large'' and ``small'' effect loci.
In practice, breeders already embellish the ``animal model'' (essentially, the infinitesimal model)
to predict traits
by combining both effects of known large effect loci
and calculations using a relatedness matrix.  \comment{cite}
We can study any model with simulation,
but the way forwards to theoretical understanding seems murky.

Further analysis of the infinitesimal model with other noise distributions,
as we have begun here,
could be interesting,
e.g., to see how changing the distribution of transmission noise
affects the rate of adaptive evolution,
levels of genetic load,
the rate of fixation,
and the strength of linked selection.
However,
we have seen that the assumption of the infinitesimal model
implies a sort of ``blending inheritance''
for the large effect alleles,
and so such work must be accompanied by simulations
to see if the predictions are borne out under concrete models of genetic inheritance.
Another open question is whether there is some set of assumptions
(perhaps involving linkage, pleiotropy, and/or environmental interactions with genetic effects)
which leads to these non-Gaussian infinitesimal models.
Finally, it may well be that there is a clever way to set up a trait-only model of evolution
that is both insensitive to the underlying genetics
and does not rely on the Gaussian central limit theorem.

Finally: above we've most often used the Cauchy distribution
not because it seems most realistic
(indeed data suggests the L\'evy stable distribution with $\alpha=3/2$ might be better)
but for convenience and to make effects more obvious.

\subsection*{Acknowledgements}
Thanks go to Nate Pope for useful discussion
and to Gregor Gorjanc for references to the literature.

\bibliographystyle{plainnat}
\bibliography{refs}

\appendix
\setcounter{table}{0}
\renewcommand{\thetable}{S\arabic{table}}
\setcounter{figure}{0}
\renewcommand{\thefigure}{S\arabic{figure}}

\begin{figure}
    \begin{center}
    \includegraphics{snp_effects/unfiltered_results_10}
    \end{center}
    \caption{
        Estimated values of the tail exponent, $\alpha$,
        for 1108 illness-related binary phenotypes,
        including the 333 phenotypes removed in filtering,
        which are shown as red points in lower plots.
        \textbf{(A)} distribution of values; and plotted against
        \textbf{(B)} number of SNPs,
        \textbf{(C)} number of cases, and
        \textbf{(C)} number of non-missing subjects.
        \label{fig:unfiltered_hist}
    }
\end{figure}

\begin{figure}
    \begin{center}
        \includegraphics{sims/selected_seg_noise_small}
    \end{center}
    \caption{
        As in Figure~\ref{fig:seg_noise},
        except computed using only mutations with absolute value effect size less than 0.1.
        \label{fig:sel_seg_noise_small}
    }
\end{figure}

\end{document}
