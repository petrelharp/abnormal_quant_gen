Let's check that our estimation procedure for alpha works.

```{r fake_data}
n <- 1e3
gwas <- data.frame(minor_AF=runif(n),
                   beta=rcauchy(n)/100)

min_num <- 20
max_prop <- 0.1
```

Now let's let $(P, Z)$ be a random draw from this table, all $Z > 0$,
and $X = Z$ with probability $P$, and $X=0$ otherwise.
Here's the complementary cumulative distribution function of $X$,
i.e., if $N$ is the number of rows in the table,
$$\begin{aligned}
   \mathbb{P}\{X > x \}  
   &= \frac{1}{N} \sum_i P_i \mathbb{1}_{Z_i > x} \\
   &= \mathbb{P}\{X > 0\} - \frac{1}{N} \sum_i P_i \mathbb{1}_{Z_i \le x} \\
   &= \frac{1}{N}\sum_i P_i - \frac{1}{N} \sum_i P_i \mathbb{1}_{Z_i \le x} .
\end{aligned}$$

```{r plotit}
estim_alpha <- function (gwas, num_breaks=1001) {
    # For a sequence of value xi,
    # fits the linear model
    #  log(pxi) ~ log(xi)
    # where
    #  pxi = prob( a randomly chosen locus has effect above xi )
    # to only the 'tail', defined as those xi such that there
    # are at least min_num loci with effect above xi
    # and at most a proportion max_prop of loci with effect above xi.
    xx <- c(seq(0, 2 * quantile(abs(gwas$beta), 0.99), length.out=num_breaks), Inf)
    disc_beta <- cut(abs(gwas$beta), xx)
    num_points <- table(disc_beta)
    dpx <- tapply(gwas$minor_AF, disc_beta, sum)
    dpx[is.na(dpx)] <- 0
    p_zero <- mean(gwas$minor_AF)
    tail_prob <- p_zero - cumsum(dpx) / nrow(gwas)
    tail_nums <- nrow(gwas) - cumsum(num_points)
    x <- xx[-1]
    xlm <- lm(log(tail_prob) ~ log(x),
              subset=(is.finite(log(tail_prob))
                      & tail_nums > min_num
                      & tail_nums < max_prop * nrow(gwas)))
    return(xlm)
}

xlm <- estim_alpha(gwas)
logx <- xlm$model[[1]]
logy <- xlm$model[[2]]
plot(logx, logy, ylab='log(prob > x)', xlab='log(x)')
abline(coef(xlm))

summary(xlm)
```

## Power

Huh, how good of an estimator is this?
```{r boot}
cauchy_boots <- replicate(1000, {
    gwas <- data.frame(minor_AF=runif(n),
                       beta=rcauchy(n)/100)
    xlm <- estim_alpha(gwas)
    return(coef(xlm)) })
hist(cauchy_boots[2,], breaks=30)
abline(v=-1, col='red')
```
Looks ok.

## Gaussian

And, what if we give this Gaussian data?
```{r gboot}
gaussian_boots <- replicate(1000, {
    gwas <- data.frame(minor_AF=runif(n),
                       beta=rnorm(n)/100)
    xlm <- estim_alpha(gwas)
    return(coef(xlm)) })
hist(gaussian_boots[2,], breaks=30)
abline(v=-1, col='red')
```
Looks ok.

## t(df=1.5)

How about Student's t?
```{r tboot}
t_boots <- replicate(1000, {
    gwas <- data.frame(minor_AF=runif(n),
                       beta=rt(n, df=1.5)/100)
    xlm <- estim_alpha(gwas)
    return(coef(xlm)) })
hist(t_boots[2,], breaks=30)
abline(v=-1.5, col='red')
```
Looks ok.


## For the paper

```{r paper_fig}
pdf(file="power_demo.pdf", width=6, height=2.5, pointsize=10)
    layout(t(1:3))
    hist(-cauchy_boots[2,], breaks=30, xlab="estimated alpha", main='Cauchy')
    abline(v=1, col='red')
    hist(-t_boots[2,], breaks=30, xlab="estimated alpha", main="Student's t (df=1.5)")
    abline(v=1.5, col='red')
    hist(-gaussian_boots[2,], breaks=30, xlab="estimated alpha", main='Gaussian')
dev.off()
```
